install.packages("xlsx")
library(xlsx)
library(xlsx)
?read.xlsx
install.packages("xlsxjars")
library(xlsx)
gin<- read.xlsx("gni.xls")
gin<- read.xlsx("gni.xls", sheetIndex = 1)
gin<- read.xlsx("gni.xlsx", sheetIndex = 1)
View(gin)
gin<- read.xlsx("gni.xlsx", sheetIndex = 1)
View(gin)
gin$NA.<- NULL
View(gin)
library(mice)
tmpGin <- mice(gin)
?read.csv
gin <- read.csv("gni_csv.csv", na.strings = "-" )
View(gin)
tmpGin <- mice(gin)
View(gin)
gin <- read.csv("gni_csv.csv" )
View(gin)
tmpGin <- mice(gin)
gin2<- complete(tmpGin)
View(gin2)
?apply
?mice
(20*3.2)+(3*3.3)+(2*13)
(20*3.2)+(3*3.3)+(2*103)
161-(20*3.2)+(3*3.3)+(2*103)
(20*3.2)+(3*3.3)+(2*103)+161
(20*3.2)+(3*3.3)+(2*103)+161-260.9
?file.info
file.info("WEOApr2017alla.xls")
file.info("WEOApr2017alla.xls", extra_cols = TRUE)
file.info("WEOApr2017alla.xls", extra_cols = F)
file.access(c("WEOApr2017alla.xls")
)
file.info("WEOApr2017alla.xls")$mtime
file.info("WEOApr2017alla.xls")$ctime
file.info("WEOApr2017alla.xls")$uname
file.info("WEOApr2017alla.xls")$grname
library(XML)
install.packages("XML")
library(XML)
install.packages("XML")
install.packages("XML")
library(XML)
xl <- "WEOApr2017alla.xls"
tmp <- tempfile(fileext=".zip")
xl <- path.expand(xl)
ok <- file.copy(xl, tmp)
tmpdir <- tempfile()
fils <- unzip(tmp, exdir=tmpdir)
fils <- unzip(tmp, exdir=tmpdir)
?slot
?slot
install.packages("RJSDMX")
library(RJSDMX)
providers <- getProviders()
providers
imf2<- getFlows("IMF2")
imf2<- getFlows("IMF2", "*outlook*")
imf2<- getFlows("IMF2")
imf2<- getFlows("IMF2",'*Outlook*')
imf <-getFlows('IMF','*Outlook*')
imf <-getFlows('IMF')
providers
imfcentral <- getFlows("IMF_SMDX_CENTRAL", '*Outlook*')
imfcentral <- getFlows("IMF_SDMX_CENTRAL", '*Outlook*')
my_ts=getSDMX('ECB','EXR.A.USD.EUR.SP00.A')
getFlows('WB')
getDimensions('WB', 'WDI')
getCodes('WB', 'WDI', 'SERIES')
DF <- getTimeSeriesTable('WB', 'SM_POP_TOTL_ZS', start=2010, end=2014)
DF <- getTimeSeriesTable('WB', 'SM_POP_TOTL_ZS', start='2010', end='2014')
DF <- getTimeSeriesTable('WB', 'WDI.SM_POP_TOTL_ZS', start='2010', end='2014')
DF <- getSDMX('WB', 'WDI.SM_POP_TOTL_ZS', start='2010', end='2014')
DF <- getSDMX('WB', 'WDI/SM_POP_TOTL_ZS', start='2010', end='2014')
DF <- getSDMX('WB', 'SM_POP_TOTL_ZS', start='2010', end='2014')
getProviders()
getFlows('WB')
getCodes('WB', 'WDI')
install.packages("RJSDMX")
library(RJSDMX)
install.packages("RJSDMX")
library(RJSDMX)
providers <- getProviders()
providers
getFlows("WITS")
getFlows("WITS", pattern = "")
getFlows("WITS", pattern = "*trade*")
getFlows("WITS", pattern = "wbg_wits")
library(jsonlite)
four <- fromJSON("http://wits.worldbank.org/API/V1/wits/datasource/trn/country/004")
four <- fromJSON("http://wits.worldbank.org/API/V1/wits/datasource/trn/country/004?format=JSON")
install.packages("XML")
install.packages("httr")
library(XML)
library(XML)
remove.packages("XML")
install.packages("XML")
library(XML)
library(httr)
response <- GET(http://wits.worldbank.org/API/V1/wits/datasource/trn/country/004")
response <- GET("http://wits.worldbank.org/API/V1/wits/datasource/trn/country/004")
xml <- xmlInternalTreeParse(content(responsem, type = "text"))
xml <- xmlInternalTreeParse(content(response, type = "text"))
xml
four <- fromJSON("http://wits.worldbank.org/API/V1/wits/datasource/trn/country/004?format=JSON")
four <- fromJSON("http://wits.worldbank.org/API/V1/SDMX/V21/datasource/TRN/reporter/004/partner/000/product/020110/year/all?format=JSON")
install.packages("rjson")
library(rjson)
string <- "http://comtrade.un.org/data/cache/partnerAreas.json"
reporters <- fromJSON(file=string)
reporters <- as.data.frame(t(sapply(reporters$results,rbind)))
View(reporters)
get.Comtrade <- function(url="http://comtrade.un.org/api/get?"
,maxrec=50000
,type="C"
,freq="A"
,px="HS"
,ps="now"
,r
,p
,rg="all"
,cc="TOTAL"
,fmt="json"
)
{
string<- paste(url
,"max=",maxrec,"&" #maximum no. of records returned
,"type=",type,"&" #type of trade (c=commodities)
,"freq=",freq,"&" #frequency
,"px=",px,"&" #classification
,"ps=",ps,"&" #time period
,"r=",r,"&" #reporting area
,"p=",p,"&" #partner country
,"rg=",rg,"&" #trade flow
,"cc=",cc,"&" #classification code
,"fmt=",fmt        #Format
,sep = ""
)
if(fmt == "csv") {
raw.data<- read.csv(string,header=TRUE)
return(list(validation=NULL, data=raw.data))
} else {
if(fmt == "json" ) {
raw.data<- fromJSON(file=string)
data<- raw.data$dataset
validation<- unlist(raw.data$validation, recursive=TRUE)
ndata<- NULL
if(length(data)> 0) {
var.names<- names(data[[1]])
data<- as.data.frame(t( sapply(data,rbind)))
ndata<- NULL
for(i in 1:ncol(data)){
data[sapply(data[,i],is.null),i]<- NA
ndata<- cbind(ndata, unlist(data[,i]))
}
ndata<- as.data.frame(ndata)
colnames(ndata)<- var.names
}
return(list(validation=validation,data =ndata))
}
}
}
s2 <- get.Comtrade(r="842", p="124,484", fmt="csv")
data <- s2$data
View(data)
install.packages("IMFData")
library(IMFData)
codes <- DataStructureMethod('DOT')
names(codes)
codes$CL_INDICATOR_DOT
codes$CL_AREA_DOT
codes$CL_INDICATOR_DOT
codes$CL_FREQ
startdate <- '2016-01-01'
enddate <- '2016-12-31'
filter<- list(CL_FREQ="A", CL_AREA_DOT="SA", CL_INDICATOR_DOT="TBG_USD", CL_COUNTERPART_AREA_DOT="BD", startdate, enddate, FALSE)
filter
filter<- list(CL_FREQ="A", CL_AREA_DOT="SA", CL_INDICATOR_DOT="TBG_USD", CL_COUNTERPART_AREA_DOT="BD")
results <- CompactDataMethod('DOT', filter, startdate = startdate, enddate = enddate, FALSE)
View(results)
result[1:5,]
results[1:5,]
results[1:5,1:(length(results)-1)]
results$Obs
filter<- list(CL_FREQ="M", CL_AREA_DOT="SA", CL_INDICATOR_DOT="TBG_USD", CL_COUNTERPART_AREA_DOT="BD")
results <- CompactDataMethod('DOT', filter, startdate = startdate, enddate = enddate, FALSE)
results$Obs
install.packages("RSelenium")
library(RSelenium)
checkForServer()
startServer()
remDr <- remoteDriver(remoteServerAddr = "localhost"
, port = 4445L
, browserName = "firefox"
)
remDr$getStatus()
remDr <- remoteDriver(remoteServerAddr = "localhost"
, port = 4444L
, browserName = "firefox"
)
remDr$getStatus()
remDr$open()
remDr$open()
remDr$open()
remDr$getStatus()
library(httr)
url <- 'https://unstats.un.org/sdgs/indicators/database/?area=BEN'
page <- GET(url)
set_config(config(ssl_verifypeer = 0L))
page <- GET(url)
print(http_status(page))
page_text <- content(page, as='text')
page_text
grepl('population', page_text, ignore.case = T)
install.packages("htmltab")
library(htmltab)
res <- htmltab(url)
View(res)
library(XML)
resxml <- readHTMLTable(page_text)
df <- data.frame(matrix(unlist(resxml), nrow=132, byrow=T))
df <- data.frame(matrix(unlist(resxml), byrow=T))
df <- data.frame(resxml)
View(df)
df2 <- df[, -grep("*FN*", colnames(df) )]
View(df2)
df3 <- df2[, -grep("*SortOrder*", colnames(df2))]
df3$sdgTable.Series.Description[3]
df3$sdgTable.Series.Description
strsplit(df3$sdgTable.Series.Description[3], '\r')
strsplit(df3$sdgTable.Series.Description[3], "\r\n")
strsplit(as.character(df3$sdgTable.Series.Description[3]), "\r\n")
strsplit(as.character(df3$sdgTable.Series.Description[3]), "\r\n")[1]
strsplit(as.character(df3$sdgTable.Series.Description[3]), "\r\n")[[1]][1]
strsplit(as.character(df3$sdgTable.Series.Description[100]), "\r\n")[[1]][1]
strsplit(as.character(df3$sdgTable.Series.Description[100]), "\r\n")[[1]][4]
strsplit(as.character(df3$sdgTable.Series.Description[100]), "\r\n")[[1]][5]
df3$sdgTable.Series.Description[100]
strsplit(as.character(df3$sdgTable.Series.Description[100]), "\r\n\r\n\r\n\r\n")
strsplit(as.character(df3$sdgTable.Series.Description[100]), "\r\n                    \r\n                  \r\n                \r\n                ")
strsplit(as.character(df3$sdgTable.Series.Description[100]), "\r\n")
df4<- data.frame(do.call('rbind', strsplit(as.character(df3$sdgTable.Series.Description[100]), "\r\n", fixed = T)))
View(df4)
df4<- data.frame(do.call('rbind', strsplit(as.character(df3$sdgTable.Series.Description), "\r\n", fixed = T)))
View(df4)
df4<- df4[,c(1,5)]
View(df4)
View(df3)
final <- cbind(df3[,1:4], df4, df3[, 6:length(df3)])
View(final)
colnames(final)[5] <- 'sdgTable.indicator.type'
colnames(final)[6] <- 'sdgTable.Series.Description'
View(final)
names(final) <- gsub("sdgTable", "", names(final))
final <- cbind(df3[,1:4], df4, df3[, 6:length(df3)])
colnames(final)[5] <- 'sdgTable.indicator.type'
colnames(final)[6] <- 'sdgTable.Series.Description'
names(final) <- gsub("sdgTable.", "", names(final))
View(final)
library(reshape2)
url <- 'https://unstats.un.org/sdgs/indicators/database/?area=BGD'
page <- GET(url)
print(http_status(page))
page_text <- content(page, as='text')
resxml <- readHTMLTable(page_text)
df <- data.frame(resxml)
df <- df[, -grep("*FN*", colnames(df) )] #drop all columns with footnote information
df <- df[, -grep("*SortOrder*", colnames(df))] #drop the two column with sortorder information
df<- data.frame(do.call('rbind', strsplit(as.character(df$sdgTable.Series.Description), "\r\n", fixed = T))) #split the column with 'sd' and '+' information
df4<- df[,c(1,5)]
df <- cbind(df[,1:4], df4, df[, 6:length(df)])
colnames(df)[5] <- 'sdgTable.indicator.type'
colnames(df)[6] <- 'sdgTable.Series.Description'
names(df) <- gsub("sdgTable.", "", names(df))
url <- 'https://unstats.un.org/sdgs/indicators/database/?area=BGD'
page <- GET(url)
library(httr) # to scrape the page
library(XML) # to produce table
library(reshape2)
set_config(config(ssl_verifypeer = 0L))
url <- 'https://unstats.un.org/sdgs/indicators/database/?area=BGD'
page <- GET(url)
print(http_status(page))
page_text <- content(page, as='text')
resxml <- readHTMLTable(page_text)
df <- data.frame(resxml)
df <- df[, -grep("*FN*", colnames(df) )] #drop all columns with footnote information
df <- df[, -grep("*SortOrder*", colnames(df))] #drop the two column with sortorder information
df<- data.frame(do.call('rbind', strsplit(as.character(df$sdgTable.Series.Description), "\r\n", fixed = T))) #split the column with 'sd' and '+' information
df4<- df[,c(1,5)]
df <- cbind(df[,1:4], df4, df[, 6:length(df)])
View(df)
df <- data.frame(resxml)
df <- df[, -grep("*FN*", colnames(df) )] #drop all columns with footnote information
df <- df[, -grep("*SortOrder*", colnames(df))] #drop the two column with sortorder information
df4<- data.frame(do.call('rbind', strsplit(as.character(df$sdgTable.Series.Description), "\r\n", fixed = T))) #split the column with 'sd' and '+' information
df4<- df4[,c(1,5)]
df <- cbind(df[,1:4], df4, df[, 6:length(df)])
colnames(df)[5] <- 'sdgTable.indicator.type'
colnames(df)[6] <- 'sdgTable.Series.Description'
names(df) <- gsub("sdgTable.", "", names(df))
View(df)
rm(df4)
?melt
final <- melt(df, id=c("Goal", "Target", "Indicator", "Series.Code",
"indicator.type", "Series.Description","Country.or.Area", "SIDS", "LDC", "LLDC", "Unit",
"Location", "Age.Group", "Sex", "Source.Type"), value.name = "Year")
View(final)
final <- melt(df, id=c("Goal", "Target", "Indicator", "Series.Code",
"indicator.type", "Series.Description","Country.or.Area", "SIDS", "LDC", "LLDC", "Unit",
"Location", "Age.Group", "Sex", "Source.Type"), na.rm = T)
View(final)
final <- final[!(is.na(final$value)),]
View(final)
final <- final[!(is.na(final$value))| final$value=="",]
View(final)
final$value <- as.numeric(final$value)
final <- final[!(is.na(final$value))| final$value=="",]
View(final)
final <- melt(df, id=c("Goal", "Target", "Indicator", "Series.Code",
"indicator.type", "Series.Description","Country.or.Area", "SIDS", "LDC", "LLDC", "Unit",
"Location", "Age.Group", "Sex", "Source.Type"), na.rm = T)
sapply(final,mode)
sapply(final,class)
transform(final, value = as.numeric(value))
View(final)
summary(final)
str(final)
final <- melt(df, id=c("Goal", "Target", "Indicator", "Series.Code",
"indicator.type", "Series.Description","Country.or.Area", "SIDS", "LDC", "LLDC", "Unit",
"Location", "Age.Group", "Sex", "Source.Type"), na.rm = T)
final[,final$value] <- sapply(final[,final$value], as.numeric)
final[,c(17)] <- sapply(final[,c(17)], as.numeric)
View(final)
final <- final[!(is.na(final$value)),]
View(final)
url <- 'https://unstats.un.org/sdgs/indicators/database/?area='
url
paste0(url,'BGD')
url <- paste0('https://unstats.un.org/sdgs/indicators/database/?area=', code)
warnings()
get_sdg <- function(code){
url <- paste0('https://unstats.un.org/sdgs/indicators/database/?area=', code)
page <- GET(url)
print(http_status(page))
page_text <- content(page, as='text')
resxml <- readHTMLTable(page_text)
df <- data.frame(resxml)
df <- df[, -grep("*FN*", colnames(df) )] #drop all columns with footnote information
df <- df[, -grep("*SortOrder*", colnames(df))] #drop the two column with sortorder information
df4<- data.frame(do.call('rbind', strsplit(as.character(df$sdgTable.Series.Description), "\r\n", fixed = T))) #split the column with 'sd' and '+' information
df4<- df4[,c(1,5)]
df <- cbind(df[,1:4], df4, df[, 6:length(df)])
colnames(df)[5] <- 'sdgTable.indicator.type'
colnames(df)[6] <- 'sdgTable.Series.Description'
names(df) <- gsub("sdgTable.", "", names(df))
rm(df4)
final <- melt(df, id=c("Goal", "Target", "Indicator", "Series.Code",
"indicator.type", "Series.Description","Country.or.Area", "SIDS", "LDC", "LLDC", "Unit",
"Location", "Age.Group", "Sex", "Source.Type"), na.rm = T)
final[,c(17)] <- sapply(final[,c(17)], as.numeric)
final <- final[!(is.na(final$value)),]
return(final)
}
kaz <- get_sdg('KAZ')
View(kaz)
get_sdg <- function(code){
url <- paste0('https://unstats.un.org/sdgs/indicators/database/?area=', code)
page <- GET(url)
if(http_status(page)$category != "Success"){
message <- paste("Error with : ", code)
print(message)
}
else {
page_text <- content(page, as='text')
resxml <- readHTMLTable(page_text)
df <- data.frame(resxml)
df <- df[, -grep("*FN*", colnames(df) )] #drop all columns with footnote information
df <- df[, -grep("*SortOrder*", colnames(df))] #drop the two column with sortorder information
df4<- data.frame(do.call('rbind', strsplit(as.character(df$sdgTable.Series.Description), "\r\n", fixed = T))) #split the column with 'sd' and '+' information
df4<- df4[,c(1,5)]
df <- cbind(df[,1:4], df4, df[, 6:length(df)])
colnames(df)[5] <- 'sdgTable.indicator.type'
colnames(df)[6] <- 'sdgTable.Series.Description'
names(df) <- gsub("sdgTable.", "", names(df))
rm(df4)
final <- melt(df, id=c("Goal", "Target", "Indicator", "Series.Code",
"indicator.type", "Series.Description","Country.or.Area", "SIDS", "LDC", "LLDC", "Unit",
"Location", "Age.Group", "Sex", "Source.Type"), na.rm = T)
final[,c(17)] <- sapply(final[,c(17)], as.numeric)
final <- final[!(is.na(final$value)),]
return(final)
}
}
kaz <- get_sdg('KAZ')
View(kaz)
idb<-'AFG, ALB, DZA, AZE, BHR, BGD, BEN, BRN, BFA, CMR, TCD, COM, CIV, DJI, EGY, GAB, GMB, GIN, GNB, GUY, IDN, IRN, IRQ, JOR, KAZ, KWT, KGZ, LBN, LBY, MYS, MDV, MLI, MRT, MAR, MOZ, NER, NGA, OMN, PAK, PSE, QAT, SAU, SEN, SLE, SOM, SDN, SUR, SYR, TJK, TGO, TUN, TUR, TKM, ARE, UGA, UZB, YEM'
strsplit(idb,', ')
strsplit(idb,', ')[[1]]
idb<-strsplit(idb,', ')[[1]]
sdg <- get_sdg('AFG')
for (code in idb){
print code
}
for (code in idb){
print(code)
}
idb<-'ALB, DZA, AZE, BHR, BGD, BEN, BRN, BFA, CMR, TCD, COM, CIV, DJI, EGY, GAB, GMB, GIN, GNB, GUY, IDN, IRN, IRQ, JOR, KAZ, KWT, KGZ, LBN, LBY, MYS, MDV, MLI, MRT, MAR, MOZ, NER, NGA, OMN, PAK, PSE, QAT, SAU, SEN, SLE, SOM, SDN, SUR, SYR, TJK, TGO, TUN, TUR, TKM, ARE, UGA, UZB, YEM'
idb<-strsplit(idb,', ')[[1]]
sdg <- get_sdg('AFG')
for (code in idb){
sdg <- rbind(sdg, get_sdg(code))
}
View(sdg)
?write.csv
write.csv(sdg, file="sdg.csv", row.names = F)
getwd
getwd()
library(IMFData)
library(IMFData)
codes <- DataStructureMethod('DOT')
names(codes)
codes$CL_INDICATOR_DOT
codes$CL_AREA_DOT
library(XML)
library(RCurl)
fileURL <-"https://www.imf.org/external/pubs/ft/weo/2017/01/weodata/WEOAprl2017.xml"
doc <- getURL(fileURL)
doc <- getURL(fileURL)
doc <- getURL(fileURL)
library(xlsx)
fileURL <- "https://www.imf.org/external/pubs/ft/weo/2017/01/weodata/WEOApr2017all.xls"
library(RCurl)
doc <- getURL(fileURL)
fileURL <- "http://www.imf.org/external/pubs/ft/weo/2017/01/weodata/WEOApr2017all.xls"
doc <- getURL(fileURL)
?read.xlsx
data <- read.xlsx(fileURL, sheetIndex = 1)
download.file(fileURL, "IMF-WEO-April17.xlsx")
fileURL <- "https://www.imf.org/external/pubs/ft/weo/2017/01/weodata/WEOApr2017all.xls"
download.file(fileURL, "IMF-WEO-April17.xls")
data <- read.xlsx("IMF-WEO-April17.xls", sheetIndex = 1)
data <- read.xlsx2("IMF-WEO-April17.xls", sheetIndex = 1)
setwd("D:/CEC/maco-dashboard/isdbdata.github.io/monograph37")
list.files()
